# Feedback

## Project Proposal

Really interesting project! I really like the aspect here of trying to identify the events that are instigators of increasing polarization. One open question here is how you will measure "polarization" -- the method you described (using semaxis to situate words along a political continuum) provides a measure for how politically oriented individual words are, but it's both not clear a.) that should be the unit of analysis (is it really the *meaning* of words that you're looking at, or the totality of discourse in a given comment -- which would suggest a document-level prediction task and b.) that a word having increasing orientation toward one pole or another should define "polarization" rather than just stronger alignment with one or the other political party. "Polarization" and "radicalization" both suggest a phenomenon that's divisive.  I'd also recommend situating this within several hypotheses that you can test -- e.g., specific events that you have reason to believe have led to increasing polarization (such as through news articles or academic articles that have argued so), and you can carry out an experiment here to test the degree to which it has done so in this data. I look forward to seeing where this goes!

For the midterm report (due Nov. 2), we'd like to see from all projects:

-- A thorough description of related work and how your proposed methods fit in to it.
-- All of the data should ideally be collected.
-- A few preliminary experiments to test whether your proposed methods are likely to be feasible or if they need adjustment.
-- Detail an evaluation strategy for assessing the performance on your method.

## Midterm Report

### Forrest Brandt, Nov 8 at 7:01pm

This is a very interesting project and topi and am very curious to see the results! The measure of polarization is clearly stated along with how the output from 0 to 1 should be interpreted. I was a little unclear if the observed random token is a random sample or how that is being identified. For example, it appears you are evaluating the polarization of a single Redditor, but not sure how that single Redditor is chosen/sampled or what time period. Looking at the three figures, it would be helpful if the Figure 2 and 3 had overlapping time periods to see if the drop in sentiment also corresponded with a spike in daily comments.

I think the evaluation strategy is well-thought out and makes use of the relevant literature. It would be helpful to provide numbers on how many labels will be manually added since subreddits like “politics” will be hard to categorize as left/right. I also had a question whether an event like #BlackLivesMatter or #MeToo will have multiple events within them and whether you will be able to compare the events with the amount of new coverage. For instance, maybe there’s an event that happened but received very little news coverage. I understand that might be hard to determine and categorize.

One thing that might be helpful is my group is also looking at comparing word2vec embeddings over time and apparently there is an issue in direct comparison where the vector dimensions might not align is your model is trained independently on two different sets of data (left/right leaning) where the vectors need to be aligned via a unified coordinate system. https://dl.acm.org/doi/10.1145/2736277.2741627 This would be helpful if you’re looking at how a word’s polarity changes over time in subreddits. Hope that’s helpful and great job!

### Jian Tong, Nov 9 at 12:54pm

Quality of Literature review: Firstly cited related literature to provide an overview of different topics about analysis of Ideological Polarization on social media or other online platform. Then introduced the polarization measure and extended the research from Twitter to Reddit. Also proposed how to define external events and measure the influence of external events. Preliminary experiments: I believe since the dataset is too large to process, and the cost to manually label of subReddit would be enormous so they didn’t show the preliminary results on the Reddit dataset but I think it would be more intuitive to exhibit some exploratory data analysis on the sampled data. Evaluation Strategy: Since the problem is not classification, they can not use standard like accuracy, F1 score, etc. They proposed a method to look at the polarization score and the subreddit. But again I think the workload will be challenging. Also I’m interested in how to analyze the influence of external events after deriving the polarization scores.

### David Bamman, Nov 12 at 9:52am

Overall great progress since the proposal -- good awareness of previous literature and limitations of these methods, and a clear path forward to completion. Sampling posts from subreddits clearly makes sense here, especially since you're assigning political leaning by subreddit identity rather than by individual user -- essentially what you're measuring is not the polarization of individuals, but polizarization of each subreddit. One interesting outcome here could be if you could quantity whether certain event *types* are more polarizing than others (e.g., presidential elections over mass shootings); the number of events you're considering within each type wouldn't really enable that kind of analysis here (the small sample sizes wouldn't have much statistical power), but you might consider expanding the number of those events if you plan to build on this work in the future.

## Final Submission

There are two deliverables left: -- Project presentation, 12/7 and 12/9 2:00-3:30 (Zoom) On Dec. 7 and 9 during class time (2:00-3:30pm), we'll have a virtual project presentation via Zoom to the rest of the class. For this session, prepare a 4-minute presentation of your project (with slides that you will share via Zoom) and be prepared to take questions from the audience (including the instructors). Your work should be relatively complete at this point. (You'll have some time to incorporate feedback you receive before your final project reports are due, but your experiments and analysis should be complete by this stage.) -- Final project report, due 12/13 (11:59pm) Your final project should be 6 pages long (not including references), single spaced in the ACL format. You'll be evaluated on the following criteria: Clarity. For the reasonably well-prepared reader, is it clear what was done and why? Is the paper well-written and well-structured? Originality. How original is the approach or problem presented in this paper? Does this paper break new ground in topic, methodology, or content? How exciting and innovative is the research it describes? Soundness. Is the technical approach sound and well-chosen? Second, can one trust the claims of the paper -- are they supported by proper experiments, proofs, or other argumentation? Substance. Does this paper have enough substance, or would it benefit from more ideas or results? Do the authors identify potential limitations of their work? Evaluation. To what extent has the application or tool been tested and evaluated? Meaningful comparison. Do the authors make clear where the presented system sits with respect to existing literature? Are the references adequate? Are the benefits of the system/application well-supported and are the limitations identified? Impact. How significant is the work described? Will novel aspects of the system result in other researchers adopting the approach in their own work? By now, you'll have read several papers that are written in this format; for further examples, see: https://aclanthology.org/events/acl-2021/#p21-1 You'll note that many of the papers follow a standard format including an "Introduction, " "Related Work, " "Data, " "Method, " "Analysis, " and "Conclusion".
